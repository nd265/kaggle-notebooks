import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
from sklearn.model_selection import train_test_split
# !pip install altair vega_datasets notebook vega
import altair as alt
alt.renderers.enable('kaggle')
alt.renderers.enable('mimetype')
from sklearn.dummy import DummyClassifier
from sklearn.model_selection import cross_validate
from sklearn.tree import DecisionTreeClassifier
get_ipython().getoutput("pip install dtreeviz")
from dtreeviz.trees import *
import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))




#passing index_col = 0 specifies that the first column in the data is the index, so just skip it 
spotify_df = pd.read_csv("../input/data.csv", index_col = 0)



train_df, test_df = train_test_split(spotify_df, test_size=0.2, random_state=123)


train_df.head()


train_df.shape, test_df.shape


train_df.info()


train_df.describe()


numeric_features = list(train_df.select_dtypes('number').columns)


# Let's plot each feature's distribution with respect to the predicted class

alt.Chart(train_df).mark_bar(opacity = 0.6).encode(
     alt.X(alt.repeat(), type='quantitative', bin=alt.Bin(maxbins=60)),
     y=alt.Y('count()', stack=False),
    color = 'target:N'
).properties(
    width=300,
    height=200
).repeat(
    numeric_features, columns = 3
) 


corr_df = train_df.corr('spearman').stack().reset_index(name='corr')
corr_df.loc[corr_df['corr'] == 1, 'corr'] = 0  # Remove diagonal
corr_df['abs'] = corr_df['corr'].abs()
corr_df


alt.Chart(corr_df).mark_circle().encode(
    x='level_0',
    y='level_1',
    size='abs',
    color=alt.Color('corr', scale=alt.Scale(scheme='blueorange', domain=(-1, 1))))


X_train,y_train = train_df.drop(columns=["song_title", "artist", "target"]), train_df['target']
X_test, y_test = test_df.drop(columns=["song_title", "artist", "target"]), test_df['target']



model = DecisionTreeClassifier()
model_scores = pd.DataFrame(cross_validate(model, X_train, y_train, cv=10, return_train_score=True))
model_scores


round(np.mean(model_scores['test_score']),3), round(np.mean(model_scores['train_score']),3)


results_dict = {
    "max_depth": [],
    "mean_train_score": [],
    "mean_cv_score": []
}

for depth in range(1, 26):
    model = DecisionTreeClassifier(max_depth=depth)
    cv_score = cross_validate(model, X_train, y_train, cv=10, return_train_score=True)
    results_dict["max_depth"].append(depth)
    results_dict["mean_cv_score"].append( np.mean(cv_score["test_score"]))
    results_dict["mean_train_score"].append( np.mean(cv_score["train_score"]))

    
result_df = pd.DataFrame(results_dict)
result_df




results = pd.melt(result_df, id_vars=['max_depth'], value_vars=['mean_train_score', 'mean_cv_score'])
results.head(4)


alt.Chart(results).mark_line().encode(
    x=alt.X('max_depth', title= 'Depth of tree'),
    y= alt.Y('value',title = 'Score', scale=alt.Scale(zero=False)),
    color=alt.Color('variable', title='Score type')
)


optimised_model = DecisionTreeClassifier(max_depth=4)
optimised_scores = pd.DataFrame(cross_validate(optimised_model, X_train, y_train, cv =10, return_train_score = True))




optimised_scores


get_ipython().getoutput("pip install dtreeviz")
# !pip install --no-cache graphviz


optimised_model.fit(X_train, y_train)
dt_viz = dtreeviz(optimised_model, 
               x_data=X_train,
               y_data=y_train,
               target_name='class',
               feature_names=X_train.columns, 
               title="Decision Tree for Spotify Dataset")
dt_viz


optimised_model = DecisionTreeClassifier(max_depth=4)
optimised_model.fit(X_train, y_train)

print(f"Score for test data: {round(optimised_model.score(X_test, y_test), 3)}")



